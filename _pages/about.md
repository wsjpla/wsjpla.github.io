---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# ü§ñ About me

Hi there üëã, I am Zirui Wang (ÁéãÂ≠êÁëû).

I graduated from the Department of Mechanical and Energy Engineering ([MEE](https://mee.sustech.edu.cn/en/)), Southern University of Science and Technology ([SUSTech](https://www.sustech.edu.cn/en/)) with a bachelor's degree.
I am currently studying for a master's degree in **robotic engineering** at SUSTech. 
My research interest includes SLAM, sensor fusion, etc.

<!-- 
# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìù Publications 
## *equal contribution

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"> </div><img src='images/LIEO.gif' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

FAST-LIEO: Fast and Real-time LiDAR-Inertial-Event-Visual Odometry, <br />**Under review**, the code and dataset will be aviliable at [[website]](https://github.com/wsjpla/FAST-LIEO).

**Zirui Wang**, Yangtao Ge, Kewei Dong, Jing Wu

<!-- **Project** -->
- In this paper we propose FAST-LIEO, a novel LiDAR-inertial-event-visual odometry. Our system supports both LIEO and LIEVO that can tightly fuse LiDAR, IMU, event camera (and standard RGB camera) measurements.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge"> </div><img src='images/tail-plus.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Are We Ready for Planetary Exploration Robots? The TAIL-Plus Dataset for SLAM in Granular Environments, ***ICRA 2024 Workshop on Field Robotics***
[[pdf]](https://arxiv.org/abs/2404.13600) [[website]](https://tailrobot.github.io/datasets/tail-plus/)

**Zirui Wang**\*, Chen Yao\*, Yangtao Ge\*, Guowei Shi\*, Ningbo Yang, Zheng Zhu, Kewei Dong, Hexiang Wei, Zhenzhong Jia, Jing Wu

<!-- **Project** -->
- In this paper we release the TAIL-Plus dataset, an extension to TAIL dataset for SLAM in planetary surface analog environments.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"> </div><img src='images/tail.gif' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

TAIL: A Terrain-Aware Multi-Modal SLAM Dataset for Robot Locomotion in Deformable Granular Environments, ***IEEE Robotics and Automation Letters***, 2024
[[preprint]](https://arxiv.org/abs/2403.16875) [[website]](https://tailrobot.github.io/)

Chen Yao\*, Yangtao Ge\*, Guowei Shi\*, **Zirui Wang**\*, Ningbo Yang, Zheng Zhu, Hexiang Wei, Yuntian Zhao, Jing Wu, Zhenzhong Jia

<!-- **Project** -->
- This paper presents TAIL (Terrain-Aware multI modaL) dataset, targeting the development of mulit-sensor fusion SLAM for robots in deformable granular scenes.
</div>
</div>

<!-- ROBIO -->

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">ROBIO 2022</div><img src='images/robio2022.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Semantic Mapping based on Visual SLAM with Object Model Replacement Visualization for Cleaning Robot, **ROBIO 2022** [[pdf]](https://ieeexplore.ieee.org/document/10011717/)

**Zirui Wang**, Haiou Liao, Zhenzhong Jia, Jing Wu


- This work proposed a semantic mapping framework based on ORB-SLAM2 for cleaning robots in indoor scenes.
</div>
</div> -->


<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">ROBIO 2022</div><img src='images/ICMRE.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Automation Extrinsic Calibration for Lidar-Photoneo in Structured Environment](https://arxiv.org/)

Yangtao Ge, Chen Yao, **Zirui Wang**, Haoran Kang, Wentao Zhang, and Jing Wu

**Project**<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- This work proposed a semantic mapping framework based on [ORB-SLAM2](https://github.com/raulmur/ORB_SLAM2) for cleaning robots in indoor scenes.
</div>
</div> -->


Automatic Extrinsic Calibration for Structured Light Camera and Repetive LiDARs, Yangtao Ge, Chen Yao, **Zirui Wang**, Haoran Kang, Wentao Zhang and Jing Wu, ***ROBOTICA***, 2024 [[pdf]](about:blank)



Development of BIM Semantic Robot Autonomous Inspection and Simulation System, Bangzhen Huang, Haiou Liao, Yangtao Ge, Wentao Zhang, Haoran Kang, **Zirui Wang**, Jing Wu, ***ICMRE 2023*** [[pdf]](https://ieeexplore.ieee.org/document/10106602/)


Semantic Mapping based on Visual SLAM with Object Model Replacement Visualization for Cleaning Robot, **Zirui Wang**, Haiou Liao, Zhenzhong Jia, Jing Wu, ***ROBIO 2022*** [[pdf]](https://ieeexplore.ieee.org/document/10011717/)


<!-- # üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üè¢ Teaching
- *2023 Spring*, ME5115 Autonomous Robotic Systems, Teaching Assistant

# üìñ Educations
- *2022.09 - 2025.06*,  Master of Science,  Southern University of Science and Technology
- *2018.09 - 2022.06*,  Bachelor of Science,   Southern University of Science and Technology


<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üíª Experience
- *2021*, Rapidamic-SUSTech Undergrad Engineer Research and Innovation Summer School  
  - Research topic: gesture control based on sEMG
- *2020*, CI-LAM (China-Italy Laboratory on Advanced Manufacturing) Summer School (remote)
- *2019*, RoboMaster University Championship

# üéÆ Others
- [bilibili](https://space.bilibili.com/12352412)
- Recently played games: CSGO, Apex, Rainbow Six: Siege, Genshin Impact, Battlefield 2042 ...

<!-- - [1.pdf](images/1.pdf)
- [33.pdf](images/2.pdf) -->